## 爬虫

### request

```python
import requests
import json
params = {
    "username": "onion"
}
headers = {
    "handsome": "onion"
}
url = "http://127.0.0.1:8080"
res = requests.get(url,params=params,headers=headers)
print(res.text)
res2 = requests.post(url,data=params) #content-type为urlencoded
print(res2.json)
print(res2.encoding)
print(res2.status_code)
print(res2.headers)
res3 = requests.post(url,json=json.dumps(params)) #content-type为json
res4 = requests.post(url,json=params)
```

### 正则表达式

```python
import re
info = "姓名:onion 生日: 2000年1月1日 本科:2017年9月1日"
#match 从字符串最开始匹配到换行结束 目的提取生日年份 group()为提取整个字符串
result = re.match(".*生日.*?(\d{4})",info)
print(result.group(1))
result2 = re.sub("\d{4}","2020",info)
print(result2)
result3 = re.search("生日.*?\d{4}",info)
print(result3.group())
name = "my name is Onion"
print(re.search("onion",name,re.IGNORECASE).group())
name2 = """my name is
onion
""" 
print(re.match(".*onion",name2,re.DOTALL).group())

```

### Beautifulsoup

pip install beautifulsoup4

```python
import re
from bs4 import BeautifulSoup
html = "..."
bs = BeautifulSoup(html,"html.parser")
title_tag = bs.title
print(title_tag.string)
div_tag = bs.div
print(div_tag.string)

first_div = bs.find("div")
div_tags = bs.findAll("div")

div_id = bs.find("div",id="info")
div_re = bs.find("div",id=re.compile("info-\d+"))
div_str = bs.find(string="python") #格式为navigatable string

children = first_div.contents
for child in children:
    print(child.name)

more_children = first_div.descendants

parents = bs.find("p",{"class":"name"}).parents
for parent in parents:
    print(parent.name)

#去掉s提取一个
post_sibling = bs.find("p",{"class":"name"}).next_siblings()
pre_sibling = bs.find("p",{"class":"name"}).previous_siblings()

name_tag = bs.find("p",{"class":"name"})
print(name_tag["class"]) #class允许多值属性，返回List
print(name_tag.get("DIY")) #自定义属性，返回字符串

```

### XPath

