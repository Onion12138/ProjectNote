> 一元线性回归

$E_{(w,b)}=\sum_{i=1}^m(y_i-(wx_i+b))^2$

- 二元函数判断凹凸性

$A=f''_{xx}(x,y),B=f''_{xy}(x,y),C=f''_{yy}(x,y)$

$A>0,AC-B^2\ge0,f(x,y)$为凸函数

$A<0,AC-B^2\ge0,f(x,y)$为凹函数

- 二元凹凸函数求最值

$f(x,y)$在开区域$D$内具有连续偏导数的凸（凹）函数，$(x_0,y_0)\in D,f'_x(x_0,y_0)=0,f'_y(x_0,y_0)=0$，则$f(x_0,y_0)$必为$f(x,y)$在$D$内的最小（大）值

- $\frac{\partial E_{(w,b)}}{\partial w}=\frac{\partial}{\partial w}[\sum_{i=1}^m(y_i-(wx_i+b))^2]=\sum_{i=1}^m\frac{\partial}{\partial w}(y_i-wx_i-b)^2=2(w\sum_{i=1}^{m}x_i^2-\sum_{i=1}^m(y_i-b)x_i)$
- $\frac{\partial E_{(w,b)}}{\partial b}=2(mb-\sum_{i=1}^m(y_i-wx_i))$
- $A=2\sum_{i=1}^mx_i^2,B=2\sum_{i=1}^mx_i,C=2m$
- $AC-B^2=4m\sum_{i=1}^m x_i^2-4(\sum_{i=1}^m x_i)^2=4m\sum_{i=1}^m x_i^2-4·m·\frac{1}{m}·(\sum_{i=1}^m x_i)^2=4m\sum_{i=1}^m(x_i^2-x_i\overline x)$
- $\sum_{i=1}^mx_i\overline x=\sum_{i=1}^m \overline x^2$
- $4m\sum_{i=1}^m(x_i^2-x_i\overline x)=m\sum_{i=1}^m(x_i^2-2x_i\overline x+\overline x^2)=4m\sum_{i=1}^{m}(x_i-\overline x)^2$
- $\frac{\partial E_{(w,b)}}{\partial b}=0 \rightarrow b = \overline y - w \overline x$
- $\frac{\partial E_{(w,b)}}{\partial w}=0 \rightarrow w(\sum_{i=1}^mx_i^2-\overline x\sum_{i=1}^mx_i) =\sum_{i=1}^my_ix_i-\overline y\sum_{i=1}^m x_i $
- $w=\frac{\sum_{i=1}^my_ix_i-\overline y\sum_{i=1}^m x_i}{\sum_{i=1}^mx_i^2-\overline x\sum_{i=1}^mx_i}=\frac{\sum_{i=1}^my_i(x_i-\overline x)}{\sum_{i=1}^mx_i^2-\frac{1}{m}(\sum_{i=1}^mx_i)^2}=\frac{\sum_{i=1}^m(y_i-\overline y)(x_i-\overline x)}{\sum_{i=1}^m(x_i-\overline x)^2}$

>  多元线性回归

$f(x_i)=(w_1,w_2,\cdots,w_d,w_{d+1})·\begin{pmatrix}x_{i1}\\x_{i2}\\ \cdots \\ x_{id} \\ 1 \end{pmatrix}$

$f(\hat x_i)=\hat w^T \hat x_i$

$E_{\hat w}=\sum_{i=1}^{m}(y_i-f(\hat x_i))^2=\sum_{i=1}^{m}(y_i-\hat w^T\hat x_i)^2=(y_1-\hat w^T \hat x_1, y_2-\hat w^T \hat x_2,\cdots,y_m-\hat w^T \hat x_m)·\begin{pmatrix}y_1-\hat w^T \hat x_1\\y_2-\hat w^T \hat x_2\\ \cdots \\ y_m-\hat w^T \hat x_m \end{pmatrix} $

$\begin{pmatrix}y_1-\hat w^T \hat x_1\\y_2-\hat w^T \hat x_2\\ \cdots \\ y_m-\hat w^T \hat x_m \end{pmatrix}=\begin{pmatrix}y_1\\y_2\\ \cdots \\ y_m\end{pmatrix}-\begin{pmatrix}\hat w^T \hat x_1\\\hat w^T \hat x_2\\ \cdots \\ \hat w^T \hat x_m \end{pmatrix}=\begin{pmatrix}y_1\\y_2\\ \cdots \\ y_m\end{pmatrix}-\begin{pmatrix}\hat x_1^T \hat w\\\hat x_2^T \hat w\\ \cdots \\ \hat x_m^T \hat w \end{pmatrix}=y-X\hat w$

$X=\begin{pmatrix}x_{11}&x_{12}&\cdots&x_{1d}&1 \\ x_{21}&x_{22}&\cdots&x_{2d}&1 \\ \cdots\\ x_{m1}&x_{m2}&\cdots&x_{md}&1\end{pmatrix}=\begin{pmatrix}\hat x_{1}^T\\ \hat x_{2}^T\\ \cdots \\ \hat x_{m}^T \end{pmatrix}$

凸集：集合$D\in R^n$，如果对于任意$x,y\in D$与任意的$a \in [0,1]$，有$ax+(1-a)y\in D$，则集合$D$为凸集

海塞矩阵：$n$元函数$f(x)$对自变量$x=(x_1,x_2,\cdots,x_n)^T$各个分量二阶偏导数$\frac{\partial^2f(x)}{\partial x_i \partial x_j}$都存在，则称函数$f(x)$在$x$处二阶可导，矩阵

$\nabla^2f(x)=\begin{pmatrix}\frac{\partial^2f(x)}{\partial x_1^2}&\frac{\partial^2f(x)}{\partial x_1 \partial x_2}&\cdots&\frac{\partial^2f(x)}{\partial x_1 \partial x_n}\\\frac{\partial^2f(x)}{\partial x_2 \partial x_1}&\frac{\partial^2f(x)}{\partial x_2^2}&\cdots&\frac{\partial^2f(x)}{\partial x_2 \partial x_n}\\\cdots\\\frac{\partial^2f(x)}{\partial x_n \partial x_1}&\frac{\partial^2f(x)}{\partial x_n \partial x_2}&\cdots&\frac{\partial^2f(x)}{\partial x_n^2}\end{pmatrix}$

为$f(x)$在$x$处的二阶导数，或海塞矩阵。若$f(x)$对$x$各变元所有二阶偏导数都连续，则$\frac{\partial^2f(x)}{\partial x_i \partial x_j}=\frac{\partial^2f(x)}{\partial x_j \partial x_i}$，此时该矩阵为对称矩阵

多元实值函数凹凸性：

设$D\subset R^n$是非空开凸集，$f:D\subset R^n \rightarrow R$，且$f(x)$在$D$上二阶连续可导，如果$f(x)$的海塞矩阵在$D$上是正定的，则$f(x)$是$D$上严格凸函数

凸充分性定理：

若$f:R^n \rightarrow R$是凸函数，且$f(x)$一阶连续可微，则$x^*$是全局解的充分必要条件是$\nabla f(x^*)=0$

矩阵微分公式：

$\frac{\partial x^T a}{\partial x}=\frac{\partial a^T x}{\partial x}=\begin{pmatrix}\frac{\partial(a_1x_1+\cdots+a_nx_n)}{\partial x_1}\\\cdots\\\frac{\partial(a_1x_1+\cdots+a_nx_n)}{\partial x_n}\end{pmatrix}=\begin{pmatrix}a_1\\\cdots\\a_n\end{pmatrix}=a$

$\frac{\partial x^TBx}{\partial x}=(B+B^T)x$

求解

$\frac{\partial E_{\hat w}}{\partial \hat w}=\frac{\partial[(y-X\hat w)^T(y-X\hat w)]}{\partial \hat w}=\frac{\partial[-y^TX\hat w - \hat w^TX^Ty+\hat w^TX^TX\hat w]}{\partial \hat w}=2X^T(X\hat w-y)$

令$2X^T(X\hat w-y)=0$

$\hat w=(X^TX)^{-1}X^Ty$

二阶偏导数

$\frac{\partial^2 E_{\hat w}}{\partial \hat w \partial \hat w^T}=\frac{\partial}{\partial \hat w}(\frac{\partial E_{\hat w}}{\partial \hat w})=\frac{\partial}{\partial \hat w}(2X^T(X\hat w-y))=2X^TX$

> 对数几率回归

- 指数族分布

该分布的分布律或概率密度如下

$p(y;\eta)=b(y)exp(\eta^TT(y)-a(\eta))$

$\eta$为该分布的自然参数，$T(y)$为充分统计量，通常等于随机变量$y$，$a(\eta)$为配分函数。伯努利分布和正态分布均属于指数族分布

- 伯努利分布

$p(y)=\phi^y(1-\phi)^{1-y}=\exp(y\ln(\frac{\phi}{1-\phi})+\ln(1-\phi))$

$b(y)=1,\eta=\ln(\frac{\phi}{1-\phi}),T(y)=y,a(\eta)=-\ln(1-\phi)=\ln(1+e^\eta)$

- 广义线性模型

三条假设

1. 给定$x$，随机变量$y$服从某个指数族分布
2. 给定$x$，目标得到一个模型$h(x)$能预测出$T(y)$的期望值
3. 假设指数族分布中自然参数$\eta$和$x$成线性关系，即$\eta=w^Tx$

- 对数几率回归

$h(x)=E[T(y|x)]=E[y|x]=\phi$

$\eta=\ln(\frac{\phi}{1-\phi})$

$\phi=\frac{1}{1+e^{-\eta}}$

$h(x)=\frac{1}{1+e^{-w^Tx}}=p(y=1|x)$

- 极大似然估计

$p(y=1|x)=\frac{e^{\beta^T\hat x}}{1+e^{\beta^T\hat x}}=p_1(\hat x;\beta)$

$p(y=0|x)=\frac{1}{1+e^{\beta^T\hat x}}=p_0(\hat x;\beta)$

$p(y|x;w,b)=y·p_1(\hat x;\beta)+(1-y)·p_0(\hat x;\beta)$

$l(\beta)=\sum_{i=1}^{m}(y_i\beta^T\hat x_i-\ln(1+e^{\beta^T\hat x_i}))$

或者

$p(y|x;w,b)=[p_1(\hat x;\beta)]^y[p_0(\hat x;\beta)]^{1-y}$

$l(\beta)=\sum_{i=1}^m(y_i[\ln(p_1(\hat x;\beta))-\ln(p_0(\hat x;\beta))]+\ln(p_0(\hat x;\beta))=\sum_{i=1}^{m}(y_i\beta^T\hat x_i-\ln(1+e^{\beta^T\hat x_i})$





